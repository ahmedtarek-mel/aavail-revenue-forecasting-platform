<p align="center">
  <img src="images/AAVAIL Banner.png" width="100%">
</p>

# ğŸŸ¦ AAVAIL Revenue Forecasting Platform  

[![Python](https://img.shields.io/badge/Python-3.10-blue.svg)]()
[![Model](https://img.shields.io/badge/Model-RandomForest-success)]()
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Build](https://img.shields.io/badge/Build-Passing-brightgreen)
![Tests](https://img.shields.io/badge/Tests-PyTest-success)
![Deployment](https://img.shields.io/badge/API-Flask-informational)

---

## ğŸ“ˆ Project Overview  
This project implements a **production-oriented machine learning system** designed to forecast daily revenue for **AAVAIL**, a global digital streaming platform operating across multiple countries.

The system reflects a **real enterprise AI workflow**, covering the full lifecycle:
from raw transactional data ingestion to model deployment, monitoring, and testing.

**Primary Objective:**  
â¡ï¸ Predict **daily revenue** at the country level using historical transaction data  
â¡ï¸ Enable data-driven planning, budgeting, and operational decision-making

---

## ğŸ§  Business Context  
Accurate revenue forecasting is a critical component for:
- Financial planning  
- Resource allocation  
- Market performance monitoring  
- Strategic expansion decisions  

This project focuses on transforming raw transactional data into actionable revenue forecasts using time-series regression techniques.

---

## ğŸ“‚ Repository Structure  

```
AAVAIL Revenue Forecasting/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ cs-train/ # Historical transaction JSON files
â”‚ â””â”€â”€ cs-production/ # Production-style JSON samples
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ data_ingestion.py # Automated data ingestion
â”‚ â”œâ”€â”€ data_preprocessing.py # Cleaning & daily aggregation
â”‚ â”œâ”€â”€ eda.py # Exploratory data analysis
â”‚ â”œâ”€â”€ baseline.py # Baseline forecasting model
â”‚ â””â”€â”€ model.py # Machine learning model
â”‚
â”œâ”€â”€ api/
â”‚ â””â”€â”€ app.py # Flask-based REST API
â”‚
â”œâ”€â”€ tests/
â”‚ â”œâ”€â”€ test_data.py # Data pipeline tests
â”‚ â”œâ”€â”€ test_model.py # Model tests
â”‚ â””â”€â”€ test_api.py # API endpoint tests
â”‚
â”œâ”€â”€ images/
â”‚ â”œâ”€â”€ revenue_timeseries.png
â”‚ â”œâ”€â”€ top_countries.png
â”‚ â”œâ”€â”€ baseline_vs_actual.png
â”‚ â””â”€â”€ model_vs_actual.png
â”‚
â”œâ”€â”€ logs/
â”‚ â””â”€â”€ predictions.log # Prediction audit logs
â”‚
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

```

---

## ğŸ“Š Dataset  
**Source:** Transaction-level JSON data  
**Granularity:** Individual purchases  
**Final Modeling Level:** Daily aggregation per country  

Key engineered fields:
- Daily revenue  
- Transaction count  
- Engagement metrics (views)  
- Date-based features  

---

## ğŸ”§ Methodology  

### 1ï¸âƒ£ Data Ingestion
- Automated ingestion of monthly JSON files
- Schema normalization and error handling
- Robust handling of inconsistent column naming

### 2ï¸âƒ£ Data Preprocessing
- Revenue calculation
- Date parsing and normalization
- Aggregation to daily country-level metrics

### 3ï¸âƒ£ Exploratory Data Analysis
EDA was conducted to:
- Identify revenue trends and seasonality
- Compare country-level revenue contributions
- Understand temporal patterns in transactions

Key observations:
- Strong seasonal revenue spikes toward year-end
- Revenue concentration in a small number of countries
- High correlation between transactions and revenue

All visual outputs are stored in the `images/` directory.

---

## ğŸ¤– Modeling Strategy  

### Baseline Model
A simple historical-average baseline model was implemented to establish a reference performance benchmark.

### Machine Learning Model
- Algorithm: **Random Forest Regressor**
- Input: Engineered daily features
- Evaluation Metric: **Mean Absolute Error (MAE)**

**Final ML Model Performance:**
- **MAE â‰ˆ 2756**

> This is a regression problem; therefore, model performance is evaluated using MAE rather than accuracy.

---

## ğŸ“‰ Model Evaluation
Visual comparisons were created to assess:
- Actual vs baseline predictions
- Actual vs ML predictions
- Error behavior during seasonal peaks

These comparisons provide transparency into model strengths and limitations.

---

## ğŸŒ API Service  

A RESTful API was developed using **Flask** to simulate a production deployment environment.

### Available Endpoints
- `GET /` â€” Health check  
- `POST /train` â€” Train the forecasting model  
- `POST /predict` â€” Generate revenue predictions for a given country and date  

All prediction requests are logged for monitoring and traceability.

---

## ğŸ§ª Testing & Reliability

The project includes **automated unit tests** designed to ensure correctness, stability, and long-term reliability across the entire pipeline.

### âœ”ï¸ Test Coverage
Unit tests validate the following components:
- **Data ingestion & preprocessing logic**
- **Model training and execution**
- **API endpoints and request handling**

### â–¶ï¸ Running Tests
All tests can be executed using a single command:

```bash
python -m pytest

```
- Running tests before deployment ensures reproducibility, early error detection, and protection against unintended regressions.

###  ğŸ³ Containerization

- The application is fully containerized using Docker, enabling consistent execution across different environments.

### âœ”ï¸ Benefits

- Environment consistency across development and production

- Portability across operating systems and cloud platforms

- Simplified deployment and scalability

- A production-ready Dockerfile is included in the project root for seamless container builds.

### ğŸ§° Technology Stack

The project is built using a modern, production-oriented technology stack:

- Python

- Pandas, NumPy

- Scikit-learn

- Matplotlib

- Flask

- Pytest

- Docker

### ğŸ§¾ Final Notes

- This project demonstrates a real-world, production-style AI workflow, with a strong emphasis on:

- Modular architecture

- Reproducibility

- Testing & reliability

- Monitoring readiness

- Deployment-first design

- The implementation intentionally prioritizes engineering best practices and system robustness over purely academic modeling results â€” reflecting how machine learning systems are built and maintained in real production environments.